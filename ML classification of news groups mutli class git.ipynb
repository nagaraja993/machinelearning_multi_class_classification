{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Naga Raja\n",
      "[nltk_data]     Paidimarri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Naga Raja\n",
      "[nltk_data]     Paidimarri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import random\n",
    "random.seed()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"20_newsgroups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_file_text(text):\n",
    "    new_text = re.sub(\"Newsgroups:.*?\\n\", \"\", text)\n",
    "    new_text = re.sub(\"Xref:.*?\\n\", \"\", new_text)\n",
    "    new_text = re.sub(\"Path:.*?\\n\", \"\", new_text)\n",
    "    new_text = re.sub(\"Date:.*?\\n\", \"\", new_text)\n",
    "    new_text = re.sub(\"Followup-To:.*?\\n\", \"\", new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corpus_count_words(file_list):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_counter = Counter()\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            word_counter.update(file_words)\n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topic_name(file_path):\n",
    "    return file_path.parent.name\n",
    "\n",
    "def get_target(topic_name):\n",
    "    topics = ['talk.politics.mideast', 'rec.autos', 'comp.sys.mac.hardware', 'alt.atheism', 'rec.sport.baseball', \n",
    "     'comp.os.ms-windows.misc', 'rec.sport.hockey', 'sci.crypt', 'sci.med', 'talk.politics.misc', \n",
    "     'rec.motorcycles', 'comp.windows.x', 'comp.graphics', 'comp.sys.ibm.pc.hardware', 'sci.electronics',\n",
    "     'talk.politics.guns', 'sci.space', 'soc.religion.christian', 'misc.forsale', 'talk.religion.misc']\n",
    "    return topics.index(topic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm):\n",
    "    # plot the confusion matrix\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.matshow(cm, fignum=1)\n",
    "    \n",
    "    # add labels for all targets\n",
    "    num_targets = cm.shape[0]\n",
    "    plt.xticks(list(range(num_targets+1)))\n",
    "    plt.yticks(list(range(num_targets+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_files = [pth for pth in Path(DATA_DIR).glob(\"**/*\") if pth.is_file() and not pth.name.startswith(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('20_newsgroups/alt.atheism/49960')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = open('20_newsgroups/alt.atheism/49960', 'r', encoding='utf-8', errors='ignore')\n",
    "y = x.read()\n",
    "z = clean_file_text(y)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "w = tokenizer.tokenize(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:49960 alt.atheism.moderated:713 news.answers:7054 alt.answers:126\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!magnus.acs.ohio-state.edu!usenet.ins.cwru.edu!agate!spool.mu.edu!uunet!pipex!ibmpcug!mantis!mathew\\nFrom: mathew <mathew@mantis.co.uk>\\nNewsgroups: alt.atheism,alt.atheism.moderated,news.answers,alt.answers\\nSubject: Alt.Atheism FAQ: Atheist Resources\\nSummary: Books, addresses, music -- anything related to atheism\\nKeywords: FAQ, atheism, books, music, fiction, addresses, contacts\\nMessage-ID: <19930329115719@mantis.co.uk>\\nDate: Mon, 29 Mar 1993 11:57:19 GMT\\nExpires: Thu, 29 Apr 1993 11:57:19 GMT\\nFollowup-To: alt.atheism\\nDistribution: world\\nOrganization: Mantis Consultants, Cambridge. UK.\\nApproved: news-answers-request@mit.edu\\nSupersedes: <19930301143317@mantis.co.uk>\\nLines: 290\\n\\nArchive-name: atheism/resources\\nAlt-atheism-archive-name: resources\\nLast-modified: 11 December'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: mathew <mathew@mantis.co.uk>\\nSubject: Alt.Atheism FAQ: Atheist Resources\\nSummary: Books, addresses, music -- anything related to atheism\\nKeywords: FAQ, atheism, books, music, fiction, addresses, contacts\\nMessage-ID: <19930329115719@mantis.co.uk>\\nExpires: Thu, 29 Apr 1993 11:57:19 GMT\\nDistribution: world\\nOrganization: Mantis Consultants, Cambridge. UK.\\nApproved: news-answers-request@mit.edu\\nSupersedes: <19930301143317@mantis.co.uk>\\nLines: 290\\n\\nArchive-name: atheism/resources\\nAlt-atheism-archive-name: resources\\nLast-modified: 11 December 1992\\nVersion: 1.0\\n\\n                              Atheist Resources\\n\\n                      Addresses of Atheist Organizations\\n\\n                                     USA\\n\\nFREEDOM FROM RELIGION FOUNDATION\\n\\nDarwin fish bumper stickers and assorted other atheist paraphernalia are\\navailable from the Freedom From Religion Foundation in the US.\\n\\nWrite to:  FFRF, P.O. Box 750, Madison, WI 53701.\\nTelephone: (608) 256-8900\\n\\nEVOLUTION DESIGNS\\n\\nEvolution Designs'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From',\n",
       " 'mathew',\n",
       " 'mathew',\n",
       " 'mantis',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'Subject',\n",
       " 'Alt',\n",
       " 'Atheism',\n",
       " 'FAQ',\n",
       " 'Atheist',\n",
       " 'Resources',\n",
       " 'Summary',\n",
       " 'Books',\n",
       " 'addresses',\n",
       " 'music',\n",
       " 'anything',\n",
       " 'related',\n",
       " 'to',\n",
       " 'atheism',\n",
       " 'Keywords',\n",
       " 'FAQ',\n",
       " 'atheism',\n",
       " 'books',\n",
       " 'music',\n",
       " 'fiction',\n",
       " 'addresses',\n",
       " 'contacts',\n",
       " 'Message',\n",
       " 'ID',\n",
       " '19930329115719',\n",
       " 'mantis',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'Expires',\n",
       " 'Thu',\n",
       " '29',\n",
       " 'Apr',\n",
       " '1993',\n",
       " '11',\n",
       " '57',\n",
       " '19',\n",
       " 'GMT',\n",
       " 'Distribution',\n",
       " 'world',\n",
       " 'Organization',\n",
       " 'Mantis',\n",
       " 'Consultants',\n",
       " 'Cambridge',\n",
       " 'UK',\n",
       " 'Approved',\n",
       " 'news',\n",
       " 'answers',\n",
       " 'request',\n",
       " 'mit',\n",
       " 'edu',\n",
       " 'Supersedes',\n",
       " '19930301143317',\n",
       " 'mantis',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'Lines',\n",
       " '290',\n",
       " 'Archive',\n",
       " 'name',\n",
       " 'atheism',\n",
       " 'resources',\n",
       " 'Alt',\n",
       " 'atheism',\n",
       " 'archive',\n",
       " 'name',\n",
       " 'resources',\n",
       " 'Last',\n",
       " 'modified',\n",
       " '11',\n",
       " 'December',\n",
       " '1992',\n",
       " 'Version',\n",
       " '1',\n",
       " '0',\n",
       " 'Atheist',\n",
       " 'Resources',\n",
       " 'Addresses',\n",
       " 'of',\n",
       " 'Atheist',\n",
       " 'Organizations',\n",
       " 'USA',\n",
       " 'FREEDOM',\n",
       " 'FROM',\n",
       " 'RELIGION',\n",
       " 'FOUNDATION',\n",
       " 'Darwin',\n",
       " 'fish',\n",
       " 'bumper',\n",
       " 'stickers',\n",
       " 'and',\n",
       " 'assorted',\n",
       " 'other',\n",
       " 'atheist',\n",
       " 'paraphernalia',\n",
       " 'are',\n",
       " 'available',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Freedom',\n",
       " 'From',\n",
       " 'Religion',\n",
       " 'Foundation',\n",
       " 'in',\n",
       " 'the',\n",
       " 'US',\n",
       " 'Write',\n",
       " 'to',\n",
       " 'FFRF',\n",
       " 'P',\n",
       " 'O',\n",
       " 'Box',\n",
       " '750',\n",
       " 'Madison',\n",
       " 'WI',\n",
       " '53701',\n",
       " 'Telephone',\n",
       " '608',\n",
       " '256',\n",
       " '8900',\n",
       " 'EVOLUTION',\n",
       " 'DESIGNS',\n",
       " 'Evolution',\n",
       " 'Designs',\n",
       " 'sell',\n",
       " 'the',\n",
       " 'Darwin',\n",
       " 'fish',\n",
       " 'It',\n",
       " 's',\n",
       " 'a',\n",
       " 'fish',\n",
       " 'symbol',\n",
       " 'like',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'Christians',\n",
       " 'stick',\n",
       " 'on',\n",
       " 'their',\n",
       " 'cars',\n",
       " 'but',\n",
       " 'with',\n",
       " 'feet',\n",
       " 'and',\n",
       " 'the',\n",
       " 'word',\n",
       " 'Darwin',\n",
       " 'written',\n",
       " 'inside',\n",
       " 'The',\n",
       " 'deluxe',\n",
       " 'moulded',\n",
       " '3D',\n",
       " 'plastic',\n",
       " 'fish',\n",
       " 'is',\n",
       " '4',\n",
       " '95',\n",
       " 'postpaid',\n",
       " 'in',\n",
       " 'the',\n",
       " 'US',\n",
       " 'Write',\n",
       " 'to',\n",
       " 'Evolution',\n",
       " 'Designs',\n",
       " '7119',\n",
       " 'Laurel',\n",
       " 'Canyon',\n",
       " '4',\n",
       " 'North',\n",
       " 'Hollywood',\n",
       " 'CA',\n",
       " '91605',\n",
       " 'People',\n",
       " 'in',\n",
       " 'the',\n",
       " 'San',\n",
       " 'Francisco',\n",
       " 'Bay',\n",
       " 'area',\n",
       " 'can',\n",
       " 'get',\n",
       " 'Darwin',\n",
       " 'Fish',\n",
       " 'from',\n",
       " 'Lynn',\n",
       " 'Gold',\n",
       " 'try',\n",
       " 'mailing',\n",
       " 'figmo',\n",
       " 'netcom',\n",
       " 'com',\n",
       " 'For',\n",
       " 'net',\n",
       " 'people',\n",
       " 'who',\n",
       " 'go',\n",
       " 'to',\n",
       " 'Lynn',\n",
       " 'directly',\n",
       " 'the',\n",
       " 'price',\n",
       " 'is',\n",
       " '4',\n",
       " '95',\n",
       " 'per',\n",
       " 'fish',\n",
       " 'AMERICAN',\n",
       " 'ATHEIST',\n",
       " 'PRESS',\n",
       " 'AAP',\n",
       " 'publish',\n",
       " 'various',\n",
       " 'atheist',\n",
       " 'books',\n",
       " 'critiques',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Bible',\n",
       " 'lists',\n",
       " 'of',\n",
       " 'Biblical',\n",
       " 'contradictions',\n",
       " 'and',\n",
       " 'so',\n",
       " 'on',\n",
       " 'One',\n",
       " 'such',\n",
       " 'book',\n",
       " 'is',\n",
       " 'The',\n",
       " 'Bible',\n",
       " 'Handbook',\n",
       " 'by',\n",
       " 'W',\n",
       " 'P',\n",
       " 'Ball',\n",
       " 'and',\n",
       " 'G',\n",
       " 'W',\n",
       " 'Foote',\n",
       " 'American',\n",
       " 'Atheist',\n",
       " 'Press',\n",
       " '372',\n",
       " 'pp',\n",
       " 'ISBN',\n",
       " '0',\n",
       " '910309',\n",
       " '26',\n",
       " '4',\n",
       " '2nd',\n",
       " 'edition',\n",
       " '1986',\n",
       " 'Bible',\n",
       " 'contradictions',\n",
       " 'absurdities',\n",
       " 'atrocities',\n",
       " 'immoralities',\n",
       " 'contains',\n",
       " 'Ball',\n",
       " 'Foote',\n",
       " 'The',\n",
       " 'Bible',\n",
       " 'Contradicts',\n",
       " 'Itself',\n",
       " 'AAP',\n",
       " 'Based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'King',\n",
       " 'James',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Bible',\n",
       " 'Write',\n",
       " 'to',\n",
       " 'American',\n",
       " 'Atheist',\n",
       " 'Press',\n",
       " 'P',\n",
       " 'O',\n",
       " 'Box',\n",
       " '140195',\n",
       " 'Austin',\n",
       " 'TX',\n",
       " '78714',\n",
       " '0195',\n",
       " 'or',\n",
       " '7215',\n",
       " 'Cameron',\n",
       " 'Road',\n",
       " 'Austin',\n",
       " 'TX',\n",
       " '78752',\n",
       " '2973',\n",
       " 'Telephone',\n",
       " '512',\n",
       " '458',\n",
       " '1244',\n",
       " 'Fax',\n",
       " '512',\n",
       " '467',\n",
       " '9525',\n",
       " 'PROMETHEUS',\n",
       " 'BOOKS',\n",
       " 'Sell',\n",
       " 'books',\n",
       " 'including',\n",
       " 'Haught',\n",
       " 's',\n",
       " 'Holy',\n",
       " 'Horrors',\n",
       " 'see',\n",
       " 'below',\n",
       " 'Write',\n",
       " 'to',\n",
       " '700',\n",
       " 'East',\n",
       " 'Amherst',\n",
       " 'Street',\n",
       " 'Buffalo',\n",
       " 'New',\n",
       " 'York',\n",
       " '14215',\n",
       " 'Telephone',\n",
       " '716',\n",
       " '837',\n",
       " '2475',\n",
       " 'An',\n",
       " 'alternate',\n",
       " 'address',\n",
       " 'which',\n",
       " 'may',\n",
       " 'be',\n",
       " 'newer',\n",
       " 'or',\n",
       " 'older',\n",
       " 'is',\n",
       " 'Prometheus',\n",
       " 'Books',\n",
       " '59',\n",
       " 'Glenn',\n",
       " 'Drive',\n",
       " 'Buffalo',\n",
       " 'NY',\n",
       " '14228',\n",
       " '2197',\n",
       " 'AFRICAN',\n",
       " 'AMERICANS',\n",
       " 'FOR',\n",
       " 'HUMANISM',\n",
       " 'An',\n",
       " 'organization',\n",
       " 'promoting',\n",
       " 'black',\n",
       " 'secular',\n",
       " 'humanism',\n",
       " 'and',\n",
       " 'uncovering',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'black',\n",
       " 'freethought',\n",
       " 'They',\n",
       " 'publish',\n",
       " 'a',\n",
       " 'quarterly',\n",
       " 'newsletter',\n",
       " 'AAH',\n",
       " 'EXAMINER',\n",
       " 'Write',\n",
       " 'to',\n",
       " 'Norm',\n",
       " 'R',\n",
       " 'Allen',\n",
       " 'Jr',\n",
       " 'African',\n",
       " 'Americans',\n",
       " 'for',\n",
       " 'Humanism',\n",
       " 'P',\n",
       " 'O',\n",
       " 'Box',\n",
       " '664',\n",
       " 'Buffalo',\n",
       " 'NY',\n",
       " '14226',\n",
       " 'United',\n",
       " 'Kingdom',\n",
       " 'Rationalist',\n",
       " 'Press',\n",
       " 'Association',\n",
       " 'National',\n",
       " 'Secular',\n",
       " 'Society',\n",
       " '88',\n",
       " 'Islington',\n",
       " 'High',\n",
       " 'Street',\n",
       " '702',\n",
       " 'Holloway',\n",
       " 'Road',\n",
       " 'London',\n",
       " 'N1',\n",
       " '8EW',\n",
       " 'London',\n",
       " 'N19',\n",
       " '3NL',\n",
       " '071',\n",
       " '226',\n",
       " '7251',\n",
       " '071',\n",
       " '272',\n",
       " '1266',\n",
       " 'British',\n",
       " 'Humanist',\n",
       " 'Association',\n",
       " 'South',\n",
       " 'Place',\n",
       " 'Ethical',\n",
       " 'Society',\n",
       " '14',\n",
       " 'Lamb',\n",
       " 's',\n",
       " 'Conduit',\n",
       " 'Passage',\n",
       " 'Conway',\n",
       " 'Hall',\n",
       " 'London',\n",
       " 'WC1R',\n",
       " '4RH',\n",
       " 'Red',\n",
       " 'Lion',\n",
       " 'Square',\n",
       " '071',\n",
       " '430',\n",
       " '0908',\n",
       " 'London',\n",
       " 'WC1R',\n",
       " '4RL',\n",
       " 'fax',\n",
       " '071',\n",
       " '430',\n",
       " '1271',\n",
       " '071',\n",
       " '831',\n",
       " '7723',\n",
       " 'The',\n",
       " 'National',\n",
       " 'Secular',\n",
       " 'Society',\n",
       " 'publish',\n",
       " 'The',\n",
       " 'Freethinker',\n",
       " 'a',\n",
       " 'monthly',\n",
       " 'magazine',\n",
       " 'founded',\n",
       " 'in',\n",
       " '1881',\n",
       " 'Germany',\n",
       " 'IBKA',\n",
       " 'e',\n",
       " 'V',\n",
       " 'Internationaler',\n",
       " 'Bund',\n",
       " 'der',\n",
       " 'Konfessionslosen',\n",
       " 'und',\n",
       " 'Atheisten',\n",
       " 'Postfach',\n",
       " '880',\n",
       " 'D',\n",
       " '1000',\n",
       " 'Berlin',\n",
       " '41',\n",
       " 'Germany',\n",
       " 'IBKA',\n",
       " 'publish',\n",
       " 'a',\n",
       " 'journal',\n",
       " 'MIZ',\n",
       " 'Materialien',\n",
       " 'und',\n",
       " 'Informationen',\n",
       " 'zur',\n",
       " 'Zeit',\n",
       " 'Politisches',\n",
       " 'Journal',\n",
       " 'der',\n",
       " 'Konfessionslosesn',\n",
       " 'und',\n",
       " 'Atheisten',\n",
       " 'Hrsg',\n",
       " 'IBKA',\n",
       " 'e',\n",
       " 'V',\n",
       " 'MIZ',\n",
       " 'Vertrieb',\n",
       " 'Postfach',\n",
       " '880',\n",
       " 'D',\n",
       " '1000',\n",
       " 'Berlin',\n",
       " '41',\n",
       " 'Germany',\n",
       " 'For',\n",
       " 'atheist',\n",
       " 'books',\n",
       " 'write',\n",
       " 'to',\n",
       " 'IBDK',\n",
       " 'Internationaler',\n",
       " 'B',\n",
       " 'ucherdienst',\n",
       " 'der',\n",
       " 'Konfessionslosen',\n",
       " 'Postfach',\n",
       " '3005',\n",
       " 'D',\n",
       " '3000',\n",
       " 'Hannover',\n",
       " '1',\n",
       " 'Germany',\n",
       " 'Telephone',\n",
       " '0511',\n",
       " '211216',\n",
       " 'Books',\n",
       " 'Fiction',\n",
       " 'THOMAS',\n",
       " 'M',\n",
       " 'DISCH',\n",
       " 'The',\n",
       " 'Santa',\n",
       " 'Claus',\n",
       " 'Compromise',\n",
       " 'Short',\n",
       " 'story',\n",
       " 'The',\n",
       " 'ultimate',\n",
       " 'proof',\n",
       " 'that',\n",
       " 'Santa',\n",
       " 'exists',\n",
       " 'All',\n",
       " 'characters',\n",
       " 'and',\n",
       " 'events',\n",
       " 'are',\n",
       " 'fictitious',\n",
       " 'Any',\n",
       " 'similarity',\n",
       " 'to',\n",
       " 'living',\n",
       " 'or',\n",
       " 'dead',\n",
       " 'gods',\n",
       " 'uh',\n",
       " 'well',\n",
       " 'WALTER',\n",
       " 'M',\n",
       " 'MILLER',\n",
       " 'JR',\n",
       " 'A',\n",
       " 'Canticle',\n",
       " 'for',\n",
       " 'Leibowitz',\n",
       " 'One',\n",
       " 'gem',\n",
       " 'in',\n",
       " 'this',\n",
       " 'post',\n",
       " 'atomic',\n",
       " 'doomsday',\n",
       " 'novel',\n",
       " 'is',\n",
       " 'the',\n",
       " 'monks',\n",
       " 'who',\n",
       " 'spent',\n",
       " 'their',\n",
       " 'lives',\n",
       " 'copying',\n",
       " 'blueprints',\n",
       " 'from',\n",
       " 'Saint',\n",
       " 'Leibowitz',\n",
       " 'filling',\n",
       " 'the',\n",
       " 'sheets',\n",
       " 'of',\n",
       " 'paper',\n",
       " 'with',\n",
       " 'ink',\n",
       " 'and',\n",
       " 'leaving',\n",
       " 'white',\n",
       " 'lines',\n",
       " 'and',\n",
       " 'letters',\n",
       " 'EDGAR',\n",
       " 'PANGBORN',\n",
       " 'Davy',\n",
       " 'Post',\n",
       " 'atomic',\n",
       " 'doomsday',\n",
       " 'novel',\n",
       " 'set',\n",
       " 'in',\n",
       " 'clerical',\n",
       " 'states',\n",
       " 'The',\n",
       " 'church',\n",
       " 'for',\n",
       " 'example',\n",
       " 'forbids',\n",
       " 'that',\n",
       " 'anyone',\n",
       " 'produce',\n",
       " 'describe',\n",
       " 'or',\n",
       " 'use',\n",
       " 'any',\n",
       " 'substance',\n",
       " 'containing',\n",
       " 'atoms',\n",
       " 'PHILIP',\n",
       " 'K',\n",
       " 'DICK',\n",
       " 'Philip',\n",
       " 'K',\n",
       " 'Dick',\n",
       " 'Dick',\n",
       " 'wrote',\n",
       " 'many',\n",
       " 'philosophical',\n",
       " 'and',\n",
       " 'thought',\n",
       " 'provoking',\n",
       " 'short',\n",
       " 'stories',\n",
       " 'and',\n",
       " 'novels',\n",
       " 'His',\n",
       " 'stories',\n",
       " 'are',\n",
       " 'bizarre',\n",
       " 'at',\n",
       " 'times',\n",
       " 'but',\n",
       " 'very',\n",
       " 'approachable',\n",
       " 'He',\n",
       " 'wrote',\n",
       " 'mainly',\n",
       " 'SF',\n",
       " 'but',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'about',\n",
       " 'people',\n",
       " 'truth',\n",
       " 'and',\n",
       " 'religion',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'technology',\n",
       " 'Although',\n",
       " 'he',\n",
       " 'often',\n",
       " 'believed',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'met',\n",
       " 'some',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'God',\n",
       " 'he',\n",
       " 'remained',\n",
       " 'sceptical',\n",
       " 'Amongst',\n",
       " 'his',\n",
       " 'novels',\n",
       " 'the',\n",
       " 'following',\n",
       " 'are',\n",
       " 'of',\n",
       " 'some',\n",
       " 'relevance',\n",
       " 'Galactic',\n",
       " 'Pot',\n",
       " 'Healer',\n",
       " 'A',\n",
       " 'fallible',\n",
       " 'alien',\n",
       " 'deity',\n",
       " 'summons',\n",
       " 'a',\n",
       " 'group',\n",
       " 'of',\n",
       " 'Earth',\n",
       " 'craftsmen',\n",
       " 'and',\n",
       " 'women',\n",
       " 'to',\n",
       " 'a',\n",
       " 'remote',\n",
       " 'planet',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'a',\n",
       " 'giant',\n",
       " 'cathedral',\n",
       " 'from',\n",
       " 'beneath',\n",
       " 'the',\n",
       " 'oceans',\n",
       " 'When',\n",
       " 'the',\n",
       " 'deity',\n",
       " 'begins',\n",
       " 'to',\n",
       " 'demand',\n",
       " 'faith',\n",
       " 'from',\n",
       " 'the',\n",
       " 'earthers',\n",
       " 'pot',\n",
       " 'healer',\n",
       " 'Joe',\n",
       " 'Fernwright',\n",
       " 'is',\n",
       " 'unable',\n",
       " 'to',\n",
       " 'comply',\n",
       " 'A',\n",
       " 'polished',\n",
       " 'ironic',\n",
       " 'and',\n",
       " 'amusing',\n",
       " 'novel',\n",
       " 'A',\n",
       " 'Maze',\n",
       " 'of',\n",
       " 'Death',\n",
       " 'Noteworthy',\n",
       " 'for',\n",
       " 'its',\n",
       " 'description',\n",
       " 'of',\n",
       " 'a',\n",
       " 'technology',\n",
       " 'based',\n",
       " 'religion',\n",
       " 'VALIS',\n",
       " 'The',\n",
       " 'schizophrenic',\n",
       " 'hero',\n",
       " 'searches',\n",
       " 'for',\n",
       " 'the',\n",
       " 'hidden',\n",
       " 'mysteries',\n",
       " 'of',\n",
       " 'Gnostic',\n",
       " 'Christianity',\n",
       " 'after',\n",
       " 'reality',\n",
       " 'is',\n",
       " 'fired',\n",
       " 'into',\n",
       " 'his',\n",
       " 'brain',\n",
       " 'by',\n",
       " 'a',\n",
       " 'pink',\n",
       " 'laser',\n",
       " 'beam',\n",
       " 'of',\n",
       " 'unknown',\n",
       " 'but',\n",
       " 'possibly',\n",
       " 'divine',\n",
       " 'origin',\n",
       " 'He',\n",
       " 'is',\n",
       " 'accompanied',\n",
       " 'by',\n",
       " 'his',\n",
       " 'dogmatic',\n",
       " 'and',\n",
       " 'dismissively',\n",
       " 'atheist',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'assorted',\n",
       " 'other',\n",
       " 'odd',\n",
       " 'characters',\n",
       " 'The',\n",
       " 'Divine',\n",
       " 'Invasion',\n",
       " 'God',\n",
       " 'invades',\n",
       " 'Earth',\n",
       " 'by',\n",
       " 'making',\n",
       " 'a',\n",
       " 'young',\n",
       " 'woman',\n",
       " 'pregnant',\n",
       " 'as',\n",
       " 'she',\n",
       " 'returns',\n",
       " 'from',\n",
       " 'another',\n",
       " 'star',\n",
       " 'system',\n",
       " 'Unfortunately',\n",
       " 'she',\n",
       " 'is',\n",
       " 'terminally',\n",
       " 'ill',\n",
       " 'and',\n",
       " 'must',\n",
       " 'be',\n",
       " 'assisted',\n",
       " 'by',\n",
       " 'a',\n",
       " 'dead',\n",
       " 'man',\n",
       " 'whose',\n",
       " 'brain',\n",
       " 'is',\n",
       " 'wired',\n",
       " 'to',\n",
       " '24',\n",
       " 'hour',\n",
       " 'easy',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'MARGARET',\n",
       " 'ATWOOD',\n",
       " 'The',\n",
       " 'Handmaid',\n",
       " 's',\n",
       " 'Tale',\n",
       " 'A',\n",
       " 'story',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'premise',\n",
       " 'that',\n",
       " 'the',\n",
       " 'US',\n",
       " 'Congress',\n",
       " 'is',\n",
       " 'mysteriously',\n",
       " 'assassinated',\n",
       " 'and',\n",
       " 'fundamentalists',\n",
       " 'quickly',\n",
       " 'take',\n",
       " 'charge',\n",
       " 'of',\n",
       " 'the',\n",
       " 'nation',\n",
       " 'to',\n",
       " 'set',\n",
       " 'it',\n",
       " 'right',\n",
       " 'again',\n",
       " 'The',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'diary',\n",
       " 'of',\n",
       " 'a',\n",
       " 'woman',\n",
       " 's',\n",
       " 'life',\n",
       " 'as',\n",
       " 'she',\n",
       " 'tries',\n",
       " 'to',\n",
       " 'live',\n",
       " 'under',\n",
       " 'the',\n",
       " 'new',\n",
       " 'Christian',\n",
       " 'theocracy',\n",
       " 'Women',\n",
       " 's',\n",
       " 'right',\n",
       " 'to',\n",
       " 'own',\n",
       " 'property',\n",
       " 'is',\n",
       " 'revoked',\n",
       " 'and',\n",
       " 'their',\n",
       " 'bank',\n",
       " 'accounts',\n",
       " 'are',\n",
       " 'closed',\n",
       " 'sinful',\n",
       " 'luxuries',\n",
       " 'are',\n",
       " 'outlawed',\n",
       " 'and',\n",
       " 'the',\n",
       " 'radio',\n",
       " 'is',\n",
       " 'only',\n",
       " 'used',\n",
       " 'for',\n",
       " 'readings',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Bible',\n",
       " 'Crimes',\n",
       " 'are',\n",
       " 'punished',\n",
       " 'retroactively',\n",
       " 'doctors',\n",
       " 'who',\n",
       " 'performed',\n",
       " 'legal',\n",
       " 'abortions',\n",
       " 'in',\n",
       " 'the',\n",
       " 'old',\n",
       " 'world',\n",
       " 'are',\n",
       " 'hunted',\n",
       " 'down',\n",
       " 'and',\n",
       " 'hanged',\n",
       " 'Atwood',\n",
       " 's',\n",
       " 'writing',\n",
       " 'style',\n",
       " 'is',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'get',\n",
       " 'used',\n",
       " 'to',\n",
       " 'at',\n",
       " 'first',\n",
       " 'but',\n",
       " 'the',\n",
       " 'tale',\n",
       " 'grows',\n",
       " 'more',\n",
       " 'and',\n",
       " 'more',\n",
       " 'chilling',\n",
       " 'as',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'on',\n",
       " 'VARIOUS',\n",
       " 'AUTHORS',\n",
       " 'The',\n",
       " 'Bible',\n",
       " 'This',\n",
       " 'somewhat',\n",
       " 'dull',\n",
       " 'and',\n",
       " 'rambling',\n",
       " 'work',\n",
       " 'has',\n",
       " 'often',\n",
       " 'been',\n",
       " 'criticized',\n",
       " 'However',\n",
       " 'it',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'worth',\n",
       " 'reading',\n",
       " 'if',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [get_target(get_topic_name(file_path)) for file_path in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = [get_topic_name(file_path) for file_path in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = [get_topic_name(all_files[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_baseline_data(file_list, num_words = 1000):\n",
    "    # Calculate word count in corpus\n",
    "    news_cnt = corpus_count_words(file_list)\n",
    "    \n",
    "    # Select the most common numWords\n",
    "    word_list = [word for (word, freq) in news_cnt.most_common(num_words)]\n",
    "    \n",
    "    # Create a binary encoding of dataset based on the selected features (X)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            df_rows.append([1 if word in file_words else 0 for word in word_list])      \n",
    "    X = pd.DataFrame(df_rows, columns = word_list)\n",
    "    \n",
    "    # Create a dataframe of targets (y)\n",
    "    y = [get_target(get_topic_name(file_path)) for file_path in file_list]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9124812459812817\n",
      "Test accuracy: 0.6978333333333333\n"
     ]
    }
   ],
   "source": [
    "# get the baseline data\n",
    "X, y = binary_baseline_data(all_files)\n",
    "\n",
    "# split to train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# train a logistic regression classifier\n",
    "clf = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "\n",
    "# predict on train and test set\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>I</th>\n",
       "      <th>is</th>\n",
       "      <th>in</th>\n",
       "      <th>that</th>\n",
       "      <th>AX</th>\n",
       "      <th>...</th>\n",
       "      <th>friend</th>\n",
       "      <th>HP</th>\n",
       "      <th>isc</th>\n",
       "      <th>present</th>\n",
       "      <th>shall</th>\n",
       "      <th>outside</th>\n",
       "      <th>cars</th>\n",
       "      <th>weapons</th>\n",
       "      <th>Summary</th>\n",
       "      <th>recently</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10779</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17224</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7369</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16330</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8072</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10907</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6958</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9366</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17502</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11148</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12840</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19118</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18431</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8666</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19769</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17568</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16023</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11363</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14423</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13997 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       the  to  of  a  and  I  is  in  that  AX    ...     friend  HP  isc  \\\n",
       "19977    1   1   1  1    1  0   1   1     1   0    ...          0   0    0   \n",
       "10779    0   0   1  0    0  0   0   0     0   0    ...          0   0    0   \n",
       "17224    1   1   1  1    1  0   1   1     1   0    ...          0   0    0   \n",
       "7369     1   0   0  1    1  1   0   1     1   0    ...          0   0    0   \n",
       "16330    1   1   1  1    1  1   1   1     1   0    ...          1   0    0   \n",
       "8072     1   1   1  1    1  1   0   1     0   0    ...          0   0    0   \n",
       "10907    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "2788     1   1   1  1    1  1   0   0     1   0    ...          0   0    0   \n",
       "4901     1   1   1  1    1  1   1   0     0   0    ...          0   0    1   \n",
       "1180     1   1   0  1    1  1   1   0     1   0    ...          0   0    0   \n",
       "15663    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "6958     1   0   1  1    1  1   1   1     0   0    ...          0   0    0   \n",
       "6494     1   1   0  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "9366     1   1   1  1    1  1   0   1     0   0    ...          0   0    0   \n",
       "5422     1   1   1  1    1  1   0   1     1   0    ...          0   0    0   \n",
       "3493     1   1   1  1    1  1   0   1     1   0    ...          1   0    0   \n",
       "17502    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "1459     1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "12256    1   1   1  1    1  1   1   0     1   0    ...          0   0    0   \n",
       "11006    1   1   1  1    1  1   1   0     1   0    ...          0   0    0   \n",
       "5358     1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "6248     1   1   1  0    1  1   1   1     1   0    ...          0   0    0   \n",
       "9282     0   0   0  0    0  0   1   0     0   0    ...          0   0    0   \n",
       "19347    1   0   1  1    0  1   0   1     1   0    ...          0   0    0   \n",
       "11148    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "12840    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "8034     1   0   1  1    0  1   1   0     0   0    ...          0   0    0   \n",
       "1586     1   1   1  1    1  1   1   1     0   0    ...          0   0    0   \n",
       "1395     1   1   1  0    0  0   0   0     0   0    ...          0   0    0   \n",
       "10801    1   1   1  0    1  1   1   1     1   0    ...          0   0    0   \n",
       "...    ...  ..  .. ..  ... ..  ..  ..   ...  ..    ...        ...  ..  ...   \n",
       "1267     1   1   1  1    1  1   1   1     0   0    ...          1   0    0   \n",
       "1899     1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "3005     1   1   1  1    1  1   1   0     0   0    ...          0   0    0   \n",
       "19118    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "189      1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "2747     1   0   1  1    1  1   1   1     0   0    ...          0   0    0   \n",
       "18431    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "18942    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "8666     1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "6396     1   0   1  0    0  0   0   0     0   0    ...          0   0    0   \n",
       "19769    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "17568    1   1   1  1    1  0   1   1     0   0    ...          0   0    0   \n",
       "6420     0   1   1  1    1  1   1   1     0   0    ...          0   0    0   \n",
       "5051     1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "5311     1   0   1  1    1  1   1   0     0   0    ...          0   0    0   \n",
       "2433     0   0   1  1    1  1   1   1     0   0    ...          0   0    0   \n",
       "769      1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "1685     1   1   1  1    1  1   1   1     0   0    ...          0   0    0   \n",
       "8322     1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "16023    1   1   1  1    1  0   1   1     1   0    ...          0   0    0   \n",
       "11363    1   1   1  0    1  1   1   1     1   0    ...          0   0    0   \n",
       "14423    1   1   1  1    1  1   0   1     1   0    ...          0   0    0   \n",
       "4426     1   1   0  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "16850    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "6265     1   1   1  1    0  1   1   1     1   0    ...          0   0    0   \n",
       "11284    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "11964    1   1   1  1    1  1   1   0     0   0    ...          0   0    0   \n",
       "5390     1   1   1  1    1  1   0   0     1   0    ...          0   0    0   \n",
       "860      1   0   1  1    1  1   1   0     0   0    ...          0   0    0   \n",
       "15795    1   1   1  1    1  1   1   1     1   0    ...          0   0    0   \n",
       "\n",
       "       present  shall  outside  cars  weapons  Summary  recently  \n",
       "19977        0      0        0     0        0        0         0  \n",
       "10779        0      0        0     0        0        0         0  \n",
       "17224        0      0        0     0        0        0         0  \n",
       "7369         0      0        0     0        0        0         0  \n",
       "16330        0      0        0     0        0        0         0  \n",
       "8072         0      0        0     0        0        0         0  \n",
       "10907        0      0        0     0        0        0         0  \n",
       "2788         0      0        0     0        0        0         0  \n",
       "4901         0      0        0     0        0        0         0  \n",
       "1180         0      0        0     0        0        0         0  \n",
       "15663        0      0        0     0        0        0         0  \n",
       "6958         0      0        0     0        0        0         0  \n",
       "6494         0      0        0     0        0        0         0  \n",
       "9366         0      0        0     0        0        0         0  \n",
       "5422         0      0        0     0        0        0         0  \n",
       "3493         0      0        0     0        0        0         0  \n",
       "17502        0      0        0     0        0        0         0  \n",
       "1459         0      0        0     0        0        0         0  \n",
       "12256        0      0        0     0        0        0         0  \n",
       "11006        0      0        0     0        0        0         0  \n",
       "5358         0      0        0     0        0        0         0  \n",
       "6248         0      0        0     0        0        0         0  \n",
       "9282         0      0        0     0        0        0         0  \n",
       "19347        0      0        0     0        0        0         0  \n",
       "11148        0      0        0     0        0        0         0  \n",
       "12840        0      0        0     0        0        0         0  \n",
       "8034         0      0        0     0        0        0         0  \n",
       "1586         0      0        0     0        0        0         0  \n",
       "1395         0      0        0     0        0        0         0  \n",
       "10801        0      0        0     0        0        1         0  \n",
       "...        ...    ...      ...   ...      ...      ...       ...  \n",
       "1267         0      0        0     0        0        0         0  \n",
       "1899         0      0        0     0        0        0         0  \n",
       "3005         0      0        0     0        0        0         0  \n",
       "19118        0      0        0     0        0        0         1  \n",
       "189          0      0        0     0        0        0         0  \n",
       "2747         0      0        0     0        0        0         0  \n",
       "18431        0      0        0     0        0        0         0  \n",
       "18942        0      0        0     0        0        0         0  \n",
       "8666         0      0        0     0        0        0         0  \n",
       "6396         0      0        0     0        0        0         0  \n",
       "19769        1      0        0     0        0        0         0  \n",
       "17568        0      0        0     0        0        1         0  \n",
       "6420         0      0        0     0        0        0         0  \n",
       "5051         0      0        0     0        0        0         0  \n",
       "5311         0      0        0     0        0        0         0  \n",
       "2433         0      0        0     0        0        0         0  \n",
       "769          0      0        0     0        0        0         0  \n",
       "1685         0      0        0     0        0        0         0  \n",
       "8322         0      0        0     0        0        0         0  \n",
       "16023        0      0        0     0        0        1         0  \n",
       "11363        0      0        0     0        0        0         0  \n",
       "14423        0      0        0     0        0        0         0  \n",
       "4426         0      0        0     0        0        0         0  \n",
       "16850        0      0        0     0        0        0         0  \n",
       "6265         0      0        0     0        0        0         0  \n",
       "11284        1      0        1     0        0        0         0  \n",
       "11964        0      0        0     0        0        1         0  \n",
       "5390         0      0        0     0        0        1         0  \n",
       "860          0      0        0     0        0        0         0  \n",
       "15795        0      0        0     0        0        0         0  \n",
       "\n",
       "[13997 rows x 1000 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[7771:7777]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (a)\n",
    "\n",
    "Feature Set: The features are the top 1000 most common words in the entire corpus of 232013 unique words encompassing 19997 documents. \n",
    "\n",
    "The amount of data: The total data is 19997 * 1000 matrix (Excluding the y column). This is randomly split in to 70% train and 30% test. Now the train data set is 13997 * 1000 and the test data set is 6000 * 1000 matrix.\n",
    "\n",
    "Hyperparameter: The default hyperparameter for logistic regression is used here. This is c = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (b)\n",
    "\n",
    "Modify the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_improved_data(file_list, num_words = 1000):\n",
    "\n",
    "    import nltk\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    nltk.download(\"wordnet\")\n",
    "    from nltk.corpus import stopwords \n",
    "    nltk.download('stopwords')\n",
    "    sbStem = SnowballStemmer(\"english\")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    news_cnt = Counter()\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            file_words = [sbStem.stem(w) for w in file_words if w.lower() not in stopwords.words('english')]\n",
    "            #file_words = [sbStem.stem(w) for w in file_words if w.lower() not in stopwords.words('english') and len(w) > 2]\n",
    "            #file_words = [w for w in file_words if len(w) > 1]\n",
    "            #file_words = [sbStem.stem(word) for word in file_words]\n",
    "            news_cnt.update(file_words)\n",
    "   \n",
    "    word_list = [word for (word, freq) in news_cnt.most_common(num_words)]   \n",
    "    \n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            file_words = [sbStem.stem(word) for word in file_words]\n",
    "            df_rows.append([1 if word in file_words else 0 for word in word_list])      \n",
    "    X = pd.DataFrame(df_rows, columns = word_list)\n",
    "    \n",
    "\n",
    "    y = [get_target(get_topic_name(file_path)) for file_path in file_list]\n",
    "      \n",
    "    #X = None\n",
    "    #y = None\n",
    "    \n",
    "    # validate return types\n",
    "    assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"return types\"\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (c)\n",
    "\n",
    "Modify the following partial code to calculate the train and test accuracy and answer the question in the markdown cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Naga Raja\n",
      "[nltk_data]     Paidimarri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Naga Raja\n",
      "[nltk_data]     Paidimarri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# get the baseline data\n",
    "X, y = binary_improved_data(all_files)\n",
    "\n",
    "\n",
    "# split to train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# train a logistic regression classifier\n",
    "clf = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "\n",
    "# predict on train and test set\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The new improved baseline**\n",
    "\n",
    "1. Train Accuracy is 0.9326\n",
    "2. Test Accuracy is 0.7435 \n",
    "\n",
    "**The previous baseline**\n",
    "\n",
    "1. Train accuracy: 0.9124\n",
    "2. Test accuracy: 0.6978\n",
    "\n",
    "We can clearly see that both train(2%) and test accuracy (5%) are improved. Even the difference(gap) in the accuracy is reduced from 21% to 19%. So, the modifications made have improved the accuracy considerabily. \n",
    "\n",
    "The improvement in the performance is due to the following changes in the code:\n",
    "1. Snowball stemmer has been used to stem the words\n",
    "2. Stop words are removed as these are not specific to any document.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (d)\n",
    "\n",
    "Modify the partial code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mean_ci(X, y, num_tests):\n",
    "    # train_results is a list of train accuracy results for the differrent random splits of the dataset\n",
    "    train_results = []\n",
    "    \n",
    "    # test_results is a list of test accuracy results for the differrent random splits of the dataset\n",
    "    test_results = []\n",
    "    \n",
    "    for i in range(0,num_tests):\n",
    "    \n",
    "        # split to train and test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,1000))\n",
    "\n",
    "        # train a logistic regression classifier\n",
    "        clf = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "\n",
    "   \n",
    "        y_train_predict = clf.predict(X_train)\n",
    "        y_test_predict = clf.predict(X_test)\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "        train_results.append(train_accuracy)\n",
    "        test_results.append(test_accuracy)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_mean = np.mean(train_results)\n",
    "    train_ci_low, train_ci_high = stats.t.interval(0.95, len(train_results)-1, loc=train_mean, scale=stats.sem(train_results))\n",
    "    \n",
    "\n",
    "    test_mean = np.mean(test_results)\n",
    "    test_ci_low, test_ci_high = stats.t.interval(0.95, len(test_results)-1, loc=test_mean, scale=stats.sem(test_results))\n",
    "    \n",
    "\n",
    "    assert isinstance(train_mean, float) and isinstance(train_ci_low, float) and isinstance(train_ci_high, float), \"return types\"\n",
    "    assert isinstance(test_mean, float) and isinstance(test_ci_low, float) and isinstance(test_ci_high, float), \"return types\"\n",
    "    \n",
    "    return train_mean, train_ci_low, train_ci_high, test_mean, test_ci_low, test_ci_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (e)\n",
    "\n",
    "Use the following code to calculate the mean accuracy and 95% confidence interval over 10 random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean accuracy over 10 random splits: 0.9347788811888261\n",
      "Train confidence interval over 10 random splits: [0.9334638089634528, 0.9360939534141994]\n",
      "Test mean accuracy over 10 random splits: 0.7517333333333334\n",
      "Test confidence interval over 10 random splits: [0.7479877847692368, 0.75547888189743]\n"
     ]
    }
   ],
   "source": [
    "train_mean10, train_low10, train_high10, test_mean10, test_low10, test_high10 = random_mean_ci(X, y, num_tests = 10)\n",
    "print(\"Train mean accuracy over 10 random splits: {}\".format(train_mean10))\n",
    "print(\"Train confidence interval over 10 random splits: [{}, {}]\".format(train_low10, train_high10))\n",
    "print(\"Test mean accuracy over 10 random splits: {}\".format(test_mean10))\n",
    "print(\"Test confidence interval over 10 random splits: [{}, {}]\".format(test_low10, test_high10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes\n",
    "\n",
    "They are more infomrative\n",
    "1. The earlier accuracy was only for a particular random split but averaging over 10 random splits and taking the mean gives us better understanding of the model.\n",
    "2. Assuming the t-distribution from these 10 splits we can get the 95% confidence interval. These means we are confident that 95 out of 100 times our model accuracy will be in this range for a random sample of the train set and the expected value is given by mean accuracy  \n",
    "\n",
    "\n",
    "The answer: \n",
    "\n",
    "1. Train mean accuracy over 10 random splits: 0.9347788811888261\n",
    "2. Train confidence interval over 10 random splits: [0.9334638089634528, 0.9360939534141994]\n",
    "3. Test mean accuracy over 10 random splits: 0.7517333333333334\n",
    "4. Test confidence interval over 10 random splits: [0.7479877847692368, 0.75547888189743]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (f)\n",
    "\n",
    "Modify the partial code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_cm(X, y, num_tests):\n",
    "    # cm_list is a list of confusion matrices for the different random splits of the dataset        \n",
    "    cm_list = []\n",
    "    \n",
    "    for i in range(0,num_tests):\n",
    "    \n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,1000))\n",
    "\n",
    "        clf = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "\n",
    "        y_train_predict = clf.predict(X_train)\n",
    "        y_test_predict = clf.predict(X_test)\n",
    "        \n",
    "        #print(y_test_predict)\n",
    "        #print(y_test)\n",
    "        \n",
    "        cm_list.append(confusion_matrix(y_test, y_test_predict))  \n",
    "\n",
    "    combined_cm = pd.Panel(cm_list).sum(axis=0)\n",
    "    \n",
    "    assert isinstance(combined_cm, pd.DataFrame), \"return type\"\n",
    "    \n",
    "    return combined_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (g)\n",
    "\n",
    "Use the following code to produce a confusion matrix for 10 random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJTCAYAAADKaFisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3X+wpHddJ/r3Z34kYSJIQgjyIwpYEFGuBBy5KIL8EgNyQXR1Sa27qOzOXUtd4Oq6eNkSLWur/O1atXu1RonBFaMo4A9WhVwUo7WATjCBiQm/FGFIyICRn4HJzJzP/eN0bo3jTGbmnG9/c3p4vapOne7nPN3vb5/ufvrdz9P9PNXdAQBg87bd0wMAADhbKFYAAIMoVgAAgyhWAACDKFYAAIMoVgAAg2zpYlVVl1fVu6vqfVX1siVnXVlVB6tq/zJzFlmXVNWfVtVNVXVjVb14iVnnVdVfVtUNi6wfW1bWMZnbq+qvq+oNS875QFW9q6qur6p9S866b1X9TlXdvLjfvmaJWZcubtNdP5+sqpcsMe+li8fG/qq6uqrOW2LWixc5Ny7jNp3oeVxVF1bVNVX13sXvC5aY9W2L27ZWVbtH5NxN1k8vHo/vrKrXV9V9l5j144uc66vqTVX1oGVlHfO3H6yqrqqLRmSdLK+qfrSqPnzM8+3Zy8paTP/+xevajVX1U8vKqqrfOuY2faCqrl9i1mVV9ba7lsVV9fglZj2mqt66WPb/QVXdZ1DWCV+XN7T86O4t+ZNke5L3J3l4knOS3JDky5eY9+Qkj0uyf8Jte2CSxy1O3zvJe5Z125JUki9YnN6Z5O1JnrDk2/d/JfmNJG9Ycs4Hkly07PtrkfWqJP92cfqcJPedlLs9yUeSfMmSrv/BSf4uyb0W51+T5DuXlPXoJPuT7EqyI8n/m+QRgzP+2fM4yU8ledni9MuS/OQSsx6V5NIkb0mye8m365lJdixO/+SSb9d9jjn9H5L80rKyFtMvSfLGJH8/8jl+ktv2o0l+cOTj8G6ynrp43J+7OH/xMv+Px/z9Z5P8yBJv15uSPGtx+tlJ3rLErL9K8vWL09+d5McHZZ3wdXkjy4+tvMbq8Une191/2913JvnNJM9bVlh3X5vk9mVd/3FZt3b3OxanP5Xkpqy/wC0jq7v704uzOxc/S9srbFU9JMk3JfmVZWXMtnhH9OQkr0yS7r6zuz8+Kf7pSd7f3X+/xIwdSe5VVTuyXnpuWVLOo5K8rbvv6O4jSf4syfNHBpzkefy8rBfjLH5/87Kyuvum7n73iOs/jaw3Lf6PSfK2JA9ZYtYnjzl7fgYtQ+5mufvzSX5oVM5p5A13kqzvSfIT3X1oMc/BJWYlSaqqknx7kquXmNVJ7lpz9IUZtAw5SdalSa5dnL4mybcOyjrZ6/IZLz+2crF6cJIPHXP+QJZUPu5JVfXQJI/N+pqkZWVsX6wGPpjkmu5eWlaS/5r1BeLaEjPu0kneVFXXVdWeJeY8PMlHk/zqYhPnr1TV+UvMO9YLMmiBeCLd/eEkP5Pkg0luTfKJ7n7TkuL2J3lyVd2vqnZl/Z3tJUvKOtYDuvvWZH3hmeTiCZmzfXeSP1pmQFX9l6r6UJJ/leRHlpjz3CQf7u4blpVxAt+32NR55ahNxSfxyCRPqqq3V9WfVdVXLzHrLk9Kclt3v3eJGS9J8tOLx8fPJPnhJWbtT/LcxelvyxKWIce9Lp/x8mMrF6s6wbSz6vg7VfUFSV6b5CXHvSMcqruPdvdlWX9H+/iqevQycqrqOUkOdvd1y7j+E3hidz8uybOSfG9VPXlJOTuyvjr6F7v7sUk+k/VVwktVVedkfQHy20vMuCDr78geluRBSc6vqu9YRlZ335T1TVbXJPnjrG/eP3K3F+KUqurlWf8/vnqZOd398u6+ZJHzfcvIWBTul2eJxe0EfjHJlya5LOtvLn52iVk7klyQ5AlJ/mOS1yzWKC3TFVnim7OF70ny0sXj46VZrN1fku/O+vL+uqxvsrtz5JWPeF3eysXqQP5pE31IlreJYrqq2pn1O+/V3f26GZmLzVdvSXL5kiKemOS5VfWBrG+6fVpV/fqSstLdtyx+H0zy+qxvPl6GA0kOHLOm73eyXrSW7VlJ3tHdty0x4xlJ/q67P9rdh5O8LsnXLiusu1/Z3Y/r7idnfRX/Mt9F3+W2qnpgkix+D9n8shVU1QuTPCfJv+rFh0Am+I0M2vxyAl+a9ZJ/w2I58pAk76iqL1pSXrr7tsWbz7Ukv5zlLUeS9WXJ6xYf0fjLrK/ZH/bh/OMtNu9/S5LfWlbGwguzvuxI1t8ILu1/2N03d/czu/ursl4Y3z/quk/yunzGy4+tXKz+Kskjquphi3fuL0jy+/fwmIZYvEN5ZZKbuvvnlpx1/7u+LVRV98r6C+nNy8jq7h/u7od090Ozfn/9SXcvZe1HVZ1fVfe+63TWP8i7lG90dvdHknyoqi5dTHp6kr9ZRtZxZrzT/GCSJ1TVrsXj8ulZ/2zBUlTVxYvfX5z1Bf6yb1+yvtx44eL0C5P83oTMpauqy5P8pyTP7e47lpz1iGPOPjfLW4a8q7sv7u6HLpYjB7L+geKPLCMv+f9fLO/y/CxpObLwu0metsh9ZNa/CPOxJeY9I8nN3X1giRnJ+kqPr1+cflqW+IbpmGXItiT/OckvDbrek70un/nyY8Sn6Zf1k/XPYLwn64305UvOujrrq4EPZ/3J/KIlZn1d1jdrvjPJ9YufZy8p6yuT/PUia38GfTPkNHKfkiV+KzDrn3u6YfFz44THx2VJ9i3+j7+b5IIl5+1K8g9JvnDCffVjWX+h3J/kf2TxjaUlZf151kvpDUmevoTr/2fP4yT3S/LmrC/s35zkwiVmPX9x+lCS25K8cYlZ78v651DvWoaM+qbeibJeu3h8vDPJHyR58LKyjvv7BzL2W4Enum3/I8m7Frft95M8cIlZ5yT59cX/8h1JnrbM/2OSq5L8+1H/v7u5XV+X5LrF8/rtSb5qiVkvznoveE+Sn0hSg7JO+Lq8keVHLa4QAIBN2sqbAgEAVopiBQAwiGIFADCIYgUAMIhiBQAwyEoUqyUfrkTWCmfNzpO1enmyVitrdp6s1cvb6lkrUaySzHyAyFqtrNl5slYvT9ZqZc3Ok7V6eVs6a1WKFQDAljd1B6H3vmBn3+/B553x5T71j4dz7wt2ntFlbr/xzOa/y+Ecys6cu6HLypqfNTtP1j9V27dvKO/O/lzOqTNbFvTRoxvKWoX/o6xBeRs4nPHhPpSdtYGsDbx0us9OYOJ99sjHPfyML3Pdddd9urvvfSaX2XHGKZtwvwefl5e/9rIpWa/58geeeqZRZu+9ftvGXsw2pNcmZjkKwBATHx/bv/A+07KO/uM/TstKktQGlvir4Cx+ntWOeS9pGy36Gwtzn43wpn1nfmjSqnr3mV7GpkAAgEEUKwCAQRQrAIBBFCsAgEEUKwCAQRQrAIBBFCsAgEEUKwCAQTZVrKrq8qp6d1W9r6peNmpQAACraMPFqqq2J/nvSZ6V5MuTXFFVXz5qYAAAq2Yza6wen+R93f233X1nkt9M8rwxwwIAWD2bKVYPTvKhY84fWEz7J6pqT1Xtq6p9n/rHw5uIAwDY2jZTrE50hNJ/dqTI7t7b3bu7e/e9L9i5iTgAgK1tM8XqQJJLjjn/kCS3bG44AACrazPF6q+SPKKqHlZV5yR5QZLfHzMsAIDVs2OjF+zuI1X1fUnemGR7kiu7+8ZhIwMAWDEbLlZJ0t1/mOQPB40FAGCl2fM6AMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgm9qP1Zm6/cadec2jvmhK1gPeeu8pOUly8Mmfm5aVJH1k4sGsa2b3XpsX1f/ssJbLVSc6tOaSonbOe1of/cQnp2Vt27VrWlaSrH3u0NS8WWrH9mlZ277g/GlZydzH49RlYx+dFrXt/Ln32dodd0zNm8EaKwCAQRQrAIBBFCsAgEEUKwCAQRQrAIBBFCsAgEEUKwCAQRQrAIBBFCsAgEEUKwCAQTZVrKrqyqo6WFX7Rw0IAGBVbXaN1VVJLh8wDgCAlbepYtXd1ya5fdBYAABWms9YAQAMsmPZAVW1J8meJDkvu5YdBwBwj1n6Gqvu3tvdu7t7986cu+w4AIB7jE2BAACDbHZ3C1cneWuSS6vqQFW9aMywAABWz6Y+Y9XdV4waCADAqrMpEABgEMUKAGAQxQoAYBDFCgBgEMUKAGAQxQoAYBDFCgBgkKUfK/CecvBJd0zLOvrGB07LSpJtT//QvLCaGHXOOdOy+tChaVnrgT0v6vCRaVlZOzov6rOfnZaVzH08brvXedOy6vzzp2WtffJT07LWA+c9HlMTF45ns4nLxlmssQIAGESxAgAYRLECABhEsQIAGESxAgAYRLECABhEsQIAGESxAgAYRLECABhEsQIAGGTDxaqqLqmqP62qm6rqxqp68ciBAQCsms0cK/BIkh/o7ndU1b2TXFdV13T33wwaGwDAStnwGqvuvrW737E4/akkNyV58KiBAQCsmiGfsaqqhyZ5bJK3j7g+AIBVtJlNgUmSqvqCJK9N8pLu/uQJ/r4nyZ4kOS+7NhsHALBlbWqNVVXtzHqpenV3v+5E83T33u7e3d27d+bczcQBAGxpm/lWYCV5ZZKbuvvnxg0JAGA1bWaN1ROT/OskT6uq6xc/zx40LgCAlbPhz1h1918kqYFjAQBYafa8DgAwiGIFADCIYgUAMIhiBQAwiGIFADCIYgUAMIhiBQAwiGIFADDIpg/CfMa2bZ8S00ePTslJkm3PODAtK0luf8Mjp2Vd+Nz3T8vqQ4emZZ3NatvE/fZum7cI6bWelpXMfTwePXxkWlY+/ol5WZPVjomPx4mvMTOtfeYzU/Pu/MbdU/NmsMYKAGAQxQoAYBDFCgBgEMUKAGAQxQoAYBDFCgBgEMUKAGAQxQoAYBDFCgBgkA0Xq6o6r6r+sqpuqKobq+rHRg4MAGDVbGb//4eSPK27P11VO5P8RVX9UXe/bdDYAABWyoaLVXd3kk8vzu5c/Mw9mBcAwBayqc9YVdX2qro+ycEk13T328cMCwBg9WyqWHX30e6+LMlDkjy+qh59/DxVtaeq9lXVvsOZd7R4AIDZhnwrsLs/nuQtSS4/wd/2dvfu7t69M+eOiAMA2JI2863A+1fVfRen75XkGUluHjUwAIBVs5lvBT4wyauqanvWC9pruvsNY4YFALB6NvOtwHcmeezAsQAArDR7XgcAGESxAgAYRLECABhEsQIAGESxAgAYRLECABhEsQIAGESxAgAYZDN7Xt+YtaNzcrZtn5OTJL02LyvJhf/He6dlPemGz07L+vPLzp+Wtf1+F07LSpKjH/3otKw+Ouk5lqS2n73Ps6lm3raqeVEzHx+Z+9g/a8187Uxyzhv3Tc2bwRorAIBBFCsAgEEUKwCAQRQrAIBBFCsAgEEUKwCAQRQrAIBBFCsAgEEUKwCAQRQrAIBBNl2sqmp7Vf11Vb1hxIAAAFbViDVWL05y04DrAQBYaZsqVlX1kCTflORXxgwHAGB1bXaN1X9N8kNJTnpo9qraU1X7qmrf4RzaZBwAwNa14WJVVc9JcrC7r7u7+bp7b3fv7u7dO3PuRuMAALa8zayxemKS51bVB5L8ZpKnVdWvDxkVAMAK2nCx6u4f7u6HdPdDk7wgyZ9093cMGxkAwIqxHysAgEF2jLiS7n5LkreMuC4AgFVljRUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCBD9mO1JfVJjws93LZz5x4Dce1zn5uW9eePude0rO1/8oBpWUefesu0rOlq3vulPnJkWtZs2+9//3lhE5dXdd5507KOfvRj07KSJDMfj1Xzslgp1lgBAAyiWAEADKJYAQAMolgBAAyiWAEADKJYAQAMolgBAAyiWAEADKJYAQAMolgBAAyyqUPaVNUHknwqydEkR7p794hBAQCsohHHCnxqd08+IBQAwNZjUyAAwCCbLVad5E1VdV1V7RkxIACAVbXZTYFP7O5bquriJNdU1c3dfe2xMywK154kOS+7NhkHALB1bWqNVXffsvh9MMnrkzz+BPPs7e7d3b17Z87dTBwAwJa24WJVVedX1b3vOp3kmUn2jxoYAMCq2cymwAckeX1V3XU9v9HdfzxkVAAAK2jDxaq7/zbJYwaOBQBgpdndAgDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIJs9ViBJ1g4duqeHsDTb73fhtKyjT71lWta33/SRaVlJ8ppHfdG8sF6bl3UWO/rRj84LW9/RMpvl/7h5s5cfZ+F9Zo0VAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgmypWVXXfqvqdqrq5qm6qqq8ZNTAAgFWz2WMF/kKSP+7uf1FV5yTZNWBMAAAracPFqqruk+TJSb4zSbr7ziR3jhkWAMDq2cymwIcn+WiSX62qv66qX6mq8weNCwBg5WymWO1I8rgkv9jdj03ymSQvO36mqtpTVfuqat/hHNpEHADA1raZYnUgyYHufvvi/O9kvWj9E929t7t3d/funTl3E3EAAFvbhotVd38kyYeq6tLFpKcn+ZshowIAWEGb/Vbg9yd59eIbgX+b5Ls2PyQAgNW0qWLV3dcn2T1oLAAAK82e1wEABlGsAAAGUawAAAZRrAAABlGsAAAGUawAAAZRrAAABlGsAAAG2eye10mS7rl5VdOijv7D7dOyZt6u1zzqi6ZlJcm/efeHpmX92qMeOi0r8+6ypNcmhiWpee87a/v2aVl95PC0rDrnnGlZSZK1ecviPnzntKypzuLXs1mssQIAGESxAgAYRLECABhEsQIAGESxAgAYRLECABhEsQIAGESxAgAYRLECABhkw8Wqqi6tquuP+flkVb1k5OAAAFbJhg9p093vTnJZklTV9iQfTvL6QeMCAFg5ozYFPj3J+7v77wddHwDAyhlVrF6Q5OpB1wUAsJI2Xayq6pwkz03y2yf5+56q2ldV+w7n0GbjAAC2rBFrrJ6V5B3dfduJ/tjde7t7d3fv3plzB8QBAGxNI4rVFbEZEABgc8WqqnYl+YYkrxszHACA1bXh3S0kSXffkeR+g8YCALDS7HkdAGAQxQoAYBDFCgBgEMUKAGAQxQoAYBDFCgBgEMUKAGAQxQoAYJBN7SB0Q6rmxOzYOSUnSdJr87KS9FpPy6ptc+6vJOmjR6dlzfZrX/bF07Ie8Zfzntbv+7ppUenDR+aFzTbxeTZz2Vg75r7ErH32c9Oy6tx5x77tQ4emZWXb9nlZZylrrAAABlGsAAAGUawAAAZRrAAABlGsAAAGUawAAAZRrAAABlGsAAAGUawAAAZRrAAABtlUsaqql1bVjVW1v6qurqrzRg0MAGDVbLhYVdWDk/yHJLu7+9FJtid5waiBAQCsms1uCtyR5F5VtSPJriS3bH5IAACracPFqrs/nORnknwwya1JPtHdbzp+vqraU1X7qmrf4Uw8QjcAwGSb2RR4QZLnJXlYkgclOb+qvuP4+bp7b3fv7u7dO3PuxkcKALDFbWZT4DOS/F13f7S7Dyd5XZKvHTMsAIDVs5li9cEkT6iqXVVVSZ6e5KYxwwIAWD2b+YzV25P8TpJ3JHnX4rr2DhoXAMDK2bGZC3f3K5K8YtBYAABWmj2vAwAMolgBAAyiWAEADKJYAQAMolgBAAyiWAEADKJYAQAMsqn9WJ2p2rkjOy66eErW0Y/9w5ScJOkjR6ZlJUm2bZ8W1UePTstK97ysqnlZSVLz3sO8/0nzbtu7f/HR07Ie+W//elpWkmRt3mO/D018nk187PeRw9OykmT7Ix4+Levo+z4wLWuqXpsat+0rv2xq3gzWWAEADKJYAQAMolgBAAyiWAEADKJYAQAMolgBAAyiWAEADKJYAQAMolgBAAyiWAEADLKpYlVVL66q/VV1Y1W9ZNSgAABW0YaLVVU9Osm/S/L4JI9J8pyqesSogQEArJrNrLF6VJK3dfcd3X0kyZ8lef6YYQEArJ7NFKv9SZ5cVferql1Jnp3kkuNnqqo9VbWvqvbdufbZTcQBAGxtOzZ6we6+qap+Msk1ST6d5IYkR04w394ke5PkC8+5uDeaBwCw1W3qw+vd/cruflx3PznJ7UneO2ZYAACrZ8NrrJKkqi7u7oNV9cVJviXJ14wZFgDA6tlUsUry2qq6X5LDSb63u/9xwJgAAFbSpopVdz9p1EAAAFadPa8DAAyiWAEADKJYAQAMolgBAAyiWAEADKJYAQAMolgBAAyy2R2EnpE+fCRHPnLblKxtu3ZNyUmSPnp0WtZ64NrcvLNRTz5sZc97jKzdOS0qj3zRddOynrP/9mlZSfKGR184NW+W2r79nh7C0hx979/e00NYebVj59S8tRtumpo3gzVWAACDKFYAAIMoVgAAgyhWAACDKFYAAIMoVgAAgyhWAACDKFYAAIMoVgAAgyhWAACDnLJYVdWVVXWwqvYfM+3Cqrqmqt67+H3BcocJALD1nc4aq6uSXH7ctJcleXN3PyLJmxfnAQA+r52yWHX3tUmOP/rp85K8anH6VUm+efC4AABWzkY/Y/WA7r41SRa/Lx43JACA1bRj2QFVtSfJniQ5L7uWHQcAcI/Z6Bqr26rqgUmy+H3wZDN2997u3t3du3fm3A3GAQBsfRstVr+f5IWL0y9M8ntjhgMAsLpOZ3cLVyd5a5JLq+pAVb0oyU8k+Yaqem+Sb1icBwD4vHbKz1h19xUn+dPTB48FAGCl2fM6AMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCBLPwjzPWXts5+dllXbt0/LSpI+cmReWNW0qO0X3W9a1tF/uH1a1my1bd591kd6WtYbvuKCaVlJcum+eYvH9z/v/tOy1iY+9rvnPT6SJGfpsnGmPnznPT2ElWeNFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCnLFZVdWVVHayq/cdM+7aqurGq1qpq93KHCACwGk5njdVVSS4/btr+JN+S5NrRAwIAWFWnPBhWd19bVQ89btpNSVJn6bGSAAA2wmesAAAGWfrh26tqT5I9SXJedi07DgDgHrP0NVbdvbe7d3f37p05d9lxAAD3GJsCAQAGOZ3dLVyd5K1JLq2qA1X1oqp6flUdSPI1Sf5nVb1x2QMFANjqTudbgVec5E+vHzwWAICVZlMgAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCBLPwjz54M6d+4xEHutp+ZNs337vKye/D+smpc18/949Oi8rMned/l9pmV96JfvOy3rku/6zLSsHF2bl5WkDx2allXnnDMta+rt2jnvdiVJHzk8NW8Ga6wAAAZRrAAABlGsAAAGUawAAAZRrAAABlGsAAAGUawAAAZRrAAABlGsAAAGOWWxqqorq+pgVe0/ZtpPV9XNVfXOqnp9Vc3bbTAAwBZ1Omusrkpy+XHTrkny6O7+yiTvSfLDg8cFALByTlmsuvvaJLcfN+1N3X1kcfZtSR6yhLEBAKyUEZ+x+u4kfzTgegAAVtqOzVy4ql6e5EiSV9/NPHuS7EmS87JrM3EAAFvahotVVb0wyXOSPL27+2TzdffeJHuT5D514UnnAwBYdRsqVlV1eZL/lOTru/uOsUMCAFhNp7O7hauTvDXJpVV1oKpelOS/Jbl3kmuq6vqq+qUljxMAYMs75Rqr7r7iBJNfuYSxAACsNHteBwAYRLECABhEsQIAGESxAgAYRLECABhEsQIAGESxAgAYRLECABhkUwdh3spqx85pWdsuuO+0rCRZ+8yH54VVzYvaOe8+O5v14SMTwyYe/nPiYzFJ+o7PTsu65LvmPaff8/88bFrWpT/wkWlZSbL26U9Py+o775yWNVPtnFsL+sjhqXkzWGMFADCIYgUAMIhiBQAwiGIFADCIYgUAMIhiBQAwiGIFADCIYgUAMIhiBQAwiGIFADDIKYtVVV1ZVQerav8x0368qt5ZVddX1Zuq6kHLHSYAwNZ3Omusrkpy+XHTfrq7v7K7L0vyhiQ/MnpgAACr5pTFqruvTXL7cdM+eczZ85NMPBIrAMDWtOHDWFfVf0nyb5J8IslT72a+PUn2JMl52bXROACALW/DH17v7pd39yVJXp3k++5mvr3dvbu7d+/MuRuNAwDY8kZ8K/A3knzrgOsBAFhpGypWVfWIY84+N8nNY4YDALC6TvkZq6q6OslTklxUVQeSvCLJs6vq0iRrSf4+yb9f5iABAFbBKYtVd19xgsmvXMJYAABWmj2vAwAMolgBAAyiWAEADKJYAQAMolgBAAyiWAEADKJYAQAMsuGDMG91dd684xKufeKT07Kmq3nd++hHbpuWlap5WUlq+/Z5WTvmPa3X7pwWNV0fPjItq87ZOS3r0h/4yLSs9//C/adlJcmX/Mt5y5DaMe8+68Nn8RPtLGSNFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIKcsVlV1ZVUdrKr9J/jbD1ZVV9VFyxkeAMDqOJ01Vlclufz4iVV1SZJvSPLBwWMCAFhJpyxW3X1tkttP8KefT/JDSXr0oAAAVtGGPmNVVc9N8uHuvuE05t1TVfuqat/hHNpIHADASthxpheoql1JXp7kmaczf3fvTbI3Se5TF1q7BQCctTayxupLkzwsyQ1V9YEkD0nyjqr6opEDAwBYNWe8xqq735Xk4rvOL8rV7u7+2MBxAQCsnNPZ3cLVSd6a5NKqOlBVL1r+sAAAVs8p11h19xWn+PtDh40GAGCF2fM6AMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCBnfEibTamkdsyJ7M9+dkpOkvSRI9Oypuu1eVFHJh6ju2pe1mR9dN59tuOBD5iWdeSWW6dlJUkfmfd/PPrxO6dl5ROfnBb1JS/46LSsJPnit+2alvXBJ9wxLWumtTvm3q4yAm0aAAAJoElEQVTt97//1LwZrLECABhEsQIAGESxAgAYRLECABhEsQIAGESxAgAYRLECABhEsQIAGESxAgAY5JTFqqqurKqDVbX/mGk/WlUfrqrrFz/PXu4wAQC2vtNZY3VVkstPMP3nu/uyxc8fjh0WAMDqOWWx6u5rk9w+YSwAACttM5+x+r6qeudiU+EFw0YEALCiNlqsfjHJlya5LMmtSX72ZDNW1Z6q2ldV+w73oQ3GAQBsfRsqVt19W3cf7e61JL+c5PF3M+/e7t7d3bt31rkbHScAwJa3oWJVVQ885uzzk+w/2bwAAJ8vdpxqhqq6OslTklxUVQeSvCLJU6rqsiSd5ANJ/s8ljhEAYCWcslh19xUnmPzKJYwFAGCl2fM6AMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCn3EHoUJ30kSNzsqrm5CTJtu3zspLUtnm3rY8enZY1VffcuIn/x233Omda1pFbb5uWNfs+m/m83nbuzmlZa3cenpZV2+cuGz/4v39mWtazbvz4tKw/+or7Tsua+tqZ5OjHPjY1bwZrrAAABlGsAAAGUawAAAZRrAAABlGsAAAGUawAAAZRrAAABlGsAAAGUawAAAY5ZbGqqiur6mBV7T9u+vdX1bur6saq+qnlDREAYDWczhqrq5JcfuyEqnpqkucl+cru/ookPzN+aAAAq+WUxaq7r01y+3GTvyfJT3T3ocU8B5cwNgCAlbLRz1g9MsmTqurtVfVnVfXVIwcFALCKdmzichckeUKSr07ymqp6ePc/P/x8Ve1JsidJzsuujY4TAGDL2+gaqwNJXtfr/jLJWpKLTjRjd+/t7t3dvXtnzt3oOAEAtryNFqvfTfK0JKmqRyY5J8nHRg0KAGAVnXJTYFVdneQpSS6qqgNJXpHkyiRXLnbBcGeSF55oMyAAwOeTUxar7r7iJH/6jsFjAQBYafa8DgAwiGIFADCIYgUAMIhiBQAwiGIFADCIYgUAMIhiBQAwiGIFADDIRg/CvPXN3BF8H52XlaTXpsYxwsTH49odd0zLOqutzXter31u7jJklp74P5ztj77ivtOy3njL9dOyvvFBl03LOltZYwUAMIhiBQAwiGIFADCIYgUAMIhiBQAwiGIFADCIYgUAMIhiBQAwiGIFADCIYgUAMMgpi1VVXVlVB6tq/zHTfquqrl/8fKCq5u1vHwBgizqdYwVeleS/Jfm1uyZ097+863RV/WySTwwfGQDAijllserua6vqoSf6W1VVkm9P8rSxwwIAWD2ns8bq7jwpyW3d/d6TzVBVe5LsSZLzsmuTcQAAW9dmP7x+RZKr726G7t7b3bu7e/fOnLvJOACArWvDa6yqakeSb0nyVeOGAwCwujazxuoZSW7u7gOjBgMAsMpOZ3cLVyd5a5JLq+pAVb1o8acX5BSbAQEAPp+czrcCrzjJ9O8cPhoAgBVmz+sAAIMoVgAAgyhWAACDKFYAAIMoVgAAgyhWAACDKFYAAINs9iDMW9a2886bF7Z9+7ysJGuf+cy8sKqJWRN7fq/Ny0qS7nlZM++ziWry86yPHJmWVTvmLYrrnHOmZc22dscd88ImPs++8UGXTcv62hvunJaVJP/rMWff49EaKwCAQRQrAIBBFCsAgEEUKwCAQRQrAIBBFCsAgEEUKwCAQRQrAIBBFCsAgEEUKwCAQU5ZrKrqyqo6WFX7j5l2WVW9raqur6p9VfX45Q4TAGDrO501Vlclufy4aT+V5Me6+7IkP7I4DwDwee2Uxaq7r01y+/GTk9xncfoLk9wyeFwAACtno4dUf0mSN1bVz2S9nH3tyWasqj1J9iTJedm1wTgAgK1vox9e/54kL+3uS5K8NMkrTzZjd+/t7t3dvXtnzt1gHADA1rfRYvXCJK9bnP7tJD68DgB83ttosbolydcvTj8tyXvHDAcAYHWd8jNWVXV1kqckuaiqDiR5RZJ/l+QXqmpHks9l8RkqAIDPZ6csVt19xUn+9FWDxwIAsNLseR0AYBDFCgBgEMUKAGAQxQoAYBDFCgBgEMUKAGAQxQoAYBDFCgBgkFPuIHSoSmrHnMi1Q4em5NwTDj9z97SsnddcNy0ra0fnZZ3Nat77pe1f9qXTso7eNPnIWVXTovrovMd+33HHtKyZ/8Mk2X7R/aZlHb3949Oy0vMeH//rMedMy0qS9/3cE6bmzWCNFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCnLFZVdWVVHayq/cdMe0xVvbWq3lVVf1BV91nuMAEAtr7TWWN1VZLLj5v2K0le1t3/W5LXJ/mPg8cFALByTlmsuvvaJLcfN/nSJNcuTl+T5FsHjwsAYOVs9DNW+5M8d3H625JcMmY4AACra6PF6ruTfG9VXZfk3knuPNmMVbWnqvZV1b7DfWiDcQAAW9+OjVyou29O8swkqapHJvmmu5l3b5K9SXKfbRf2RvIAAFbBhtZYVdXFi9/bkvznJL80clAAAKvodHa3cHWStya5tKoOVNWLklxRVe9JcnOSW5L86nKHCQCw9Z1yU2B3X3GSP/3C4LEAAKw0e14HABhEsQIAGESxAgAYRLECABhEsQIAGESxAgAYRLECABhEsQIAGGRDxwrcqEc+7uF5076rZ0YCAExjjRUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgihUAwCCKFQDAIIoVAMAgpyxWVXVJVf1pVd1UVTdW1YsX0y+sqmuq6r2L3xcsf7gAAFvX6ayxOpLkB7r7UUmekOR7q+rLk7wsyZu7+xFJ3rw4DwDweeuUxaq7b+3udyxOfyrJTUkenOR5SV61mO1VSb55WYMEAFgFZ/QZq6p6aJLHJnl7kgd0963JevlKcvHowQEArJIdpztjVX1BktcmeUl3f7KqTvdye5LsWZz9dFW9+4xHmVyU5GMbuNxGyFqtrNl5slYvT9ZqZc3Ok7V6eTOzLj3TC1R3n3qmqp1J3pDkjd39c4tp707ylO6+taoemOQt3X3GAzitQVbt6+7dy7huWaudNTtP1urlyVqtrNl5slYvb6tnnc63AivJK5PcdFepWvj9JC9cnH5hkt87k2AAgLPN6WwKfGKSf53kXVV1/WLa/53kJ5K8pqpelOSDSb5tOUMEAFgNpyxW3f0XSU72gaqnjx3OSe2dlCNr9bJm58lavTxZq5U1O0/W6uVt6azT+owVAACn5pA2AACDKFYAAIMoVgAAgyhWAACDKFYAAIMoVgAAgyhWAACD/H8c4LI9gUuZ3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm10 = random_cm(X, y, num_tests = 10)\n",
    "plot_confusion_matrix(cm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(cm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, some some classes are more confused with others.\n",
    "\n",
    "**Easily confused**\n",
    "\n",
    "Class 3:alt.atheism  & Class 19:talk.religion.misc\n",
    "\n",
    "Class 9:talk.politics.misc  & Class 19:talk.religion.misc\n",
    "\n",
    "Class 13:comp.sys.ibm.pc.hardware  & Class 2:comp.sys.mac.hardware\n",
    "\n",
    "Classes (5,11,12,13) \n",
    "\n",
    "These classes are easily confused because they have many common words. This is a drawback in the unigram approach becuase if we have common words it assumes it has significance in all the documents it occurs but not the context in which they are used.\n",
    "\n",
    "Class 17: soc.religion.christian. Is rarely confused with others.\n",
    "\n",
    "This can be due to the fact that its documents has many unique words explicit to this class\n",
    "\n",
    "\n",
    "topics \n",
    "\n",
    "['talk.politics.mideast 0', 'rec.autos 1', 'comp.sys.mac.hardware 2', 'alt.atheism 3', 'rec.sport.baseball 4', \n",
    "     'comp.os.ms-windows.misc 5', 'rec.sport.hockey 6', 'sci.crypt 7', 'sci.med 8', 'talk.politics.misc 9', \n",
    "     'rec.motorcycles 10', 'comp.windows.x 11', 'comp.graphics 12', 'comp.sys.ibm.pc.hardware 13', 'sci.electronics 14',\n",
    "     'talk.politics.guns 15 ', 'sci.space 16', 'soc.religion.christian 17', 'misc.forsale 18 ', 'talk.religion.misc 19']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (a)\n",
    "\n",
    "Modify the partial code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_num(X, y):\n",
    "    # result_list is a list of tuples (num_features, train_accuracy, test_accuracy)\n",
    "    # where numFeatures is the number of words used as features\n",
    "    result_list = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    for p in [0.1, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "        subset_size = int(p*X.shape[1])\n",
    "        X_train_subset = X_train.iloc[:, 0:subset_size]\n",
    "        X_test_subset = X_test.iloc[:, 0:subset_size]\n",
    "\n",
    "        clf = LogisticRegression(C=1.0).fit(X_train_subset, y_train)\n",
    "\n",
    "        # predict on train and test set\n",
    "        y_train_predict = clf.predict(X_train_subset)\n",
    "        y_test_predict = clf.predict(X_test_subset)\n",
    "\n",
    "        # calculate train and test accuracy\n",
    "        train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_predict)       \n",
    "        \n",
    "#         train_accuracy = None\n",
    "#         test_accuracy = None\n",
    "        # add to result_list\n",
    "        result_list.append((p, train_accuracy, test_accuracy))\n",
    "        \n",
    "    # Make a dataframe of the results\n",
    "    result_df = pd.DataFrame(result_list, columns=[\"num_features\", \"train_accuracy\", \"test_accuracy\"])\n",
    "    \n",
    "    # validate return type\n",
    "    assert isinstance(result_df, pd.DataFrame), \"return type\"\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (b)\n",
    "\n",
    "Use the following code to plot the train and test accuracy for the different feature sets sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c6f8639550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_num_df = feature_num(X, y)\n",
    "feature_num_df.plot(x=\"num_features\", y=[\"train_accuracy\", \"test_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature_num_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the train and test accuracy are increasing with increasing number of features.\n",
    "\n",
    "1. If the model has more features, in this case, the model is better able to classify different documents because it has more words (features) to learn from.\n",
    "2. Although both are increasing the test accuracy is increasing at lower rate becuase the model is overfitting on the train data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (a)\n",
    "\n",
    "Modify the partial code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyperparameter(X, y):\n",
    "    # result_list is a list of tuples (num_features, train_accuracy, test_accuracy)\n",
    "    # where numFeatures is the number of words used as features\n",
    "    result_list = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    for param in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "\n",
    "        clf = LogisticRegression(C=param).fit(X_train, y_train)\n",
    "\n",
    "        # predict on train and test set\n",
    "        y_train_predict = clf.predict(X_train)\n",
    "        y_test_predict = clf.predict(X_test)\n",
    "\n",
    "        # calculate train and test accuracy\n",
    "        train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_predict)  \n",
    "    \n",
    "#         train_accuracy = None\n",
    "#         test_accuracy = None\n",
    "        \n",
    "        # add to result_list\n",
    "        result_list.append((param, train_accuracy, test_accuracy))\n",
    "        \n",
    "    # Make a dataframe of the results\n",
    "    result_df = pd.DataFrame(result_list, columns=[\"param\", \"train_accuracy\", \"test_accuracy\"])\n",
    "    \n",
    "    # validate return type\n",
    "    assert isinstance(result_df, pd.DataFrame), \"return type\"\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (b)\n",
    "\n",
    "Use the following code to plot the train and test accuracy for the different the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c6f838a080>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_df = hyperparameter(X, y)\n",
    "param_df.plot(x=\"param\", y=[\"train_accuracy\", \"test_accuracy\"], logx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the hyper parameter the train accuracy is increasing and test accuracy reaches a maximum at c = 0.1 and starts to decrease.\n",
    "\n",
    "1. For higher c (1/regularization strength) values the regularization constant decreases and the model starts to overfit.\n",
    "2. For lower c values the regularization values are very high and this leads to penalizing weights too much. Due to this the model is not learning and test accuracy is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (a)\n",
    "\n",
    "Modify the partial code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_improved_data(file_list, num_words = 1000):\n",
    "    import nltk\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    nltk.download(\"wordnet\")\n",
    "    from nltk.corpus import stopwords \n",
    "    nltk.download('stopwords')\n",
    "    sbStem = SnowballStemmer(\"english\")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    news_cnt = Counter()\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            file_words = [sbStem.stem(w) for w in file_words if w.lower() not in stopwords.words('english')]\n",
    "            #file_words = [sbStem.stem(word) for word in file_words]\n",
    "            news_cnt.update(file_words)\n",
    "   \n",
    "   \n",
    "    word_list = [word for (word, freq) in news_cnt.most_common(num_words)]   \n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            file_words = [sbStem.stem(word) for word in file_words]\n",
    "            df_rows.append([file_words.count(word) if word in file_words else 0 for word in word_list])      \n",
    "    X = pd.DataFrame(df_rows, columns = word_list)\n",
    "\n",
    "    y = [get_target(get_topic_name(file_path)) for file_path in file_list]\n",
    "         \n",
    "#     X = None\n",
    "#     y = None\n",
    "    \n",
    "    assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"return types\"\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# df_rows.append([file_words.count(word) if word in file_words else 0 for word in word_list])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (b)\n",
    "\n",
    "Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nagaraja993\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nagaraja993\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Train mean accuracy over 10 random splits: 0.9225691219547045\n",
      "Train confidence interval over 10 random splits: [0.9186905465129387, 0.9264476973964704]\n",
      "Test mean accuracy over 10 random splits: 0.7342833333333332\n",
      "Test confidence interval over 10 random splits: [0.7308525791145616, 0.7377140875521048]\n"
     ]
    }
   ],
   "source": [
    "X_tf, y_tf = tf_improved_data(all_files)\n",
    "train_mean10, train_low10, train_high10, test_mean10, test_low10, test_high10 = random_mean_ci(X_tf, y_tf, num_tests = 10)\n",
    "print(\"Train mean accuracy over 10 random splits: {}\".format(train_mean10))\n",
    "print(\"Train confidence interval over 10 random splits: [{}, {}]\".format(train_low10, train_high10))\n",
    "print(\"Test mean accuracy over 10 random splits: {}\".format(test_mean10))\n",
    "print(\"Test confidence interval over 10 random splits: [{}, {}]\".format(test_low10, test_high10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequency encoding**\n",
    "\n",
    "1. Train mean accuracy over 10 random splits: 0.9225691219547045\n",
    "2. Train confidence interval over 10 random splits: [0.9186905465129387, 0.9264476973964704]\n",
    "3. Test mean accuracy over 10 random splits: 0.7342833333333332\n",
    "4. Test confidence interval over 10 random splits: [0.7308525791145616, 0.7377140875521048]\n",
    "\n",
    "**Binary encoding**\n",
    "\n",
    "1. Train mean accuracy over 10 random splits: 0.9347788811888261\n",
    "2. Train confidence interval over 10 random splits: [0.9334638089634528, 0.9360939534141994]\n",
    "3. Test mean accuracy over 10 random splits: 0.7517333333333334\n",
    "4. Test confidence interval over 10 random splits: [0.7479877847692368, 0.75547888189743]\n",
    "\n",
    "\n",
    "The binary encoding has both the mean train and mean test accuracy higher than frequency encoding. The confidence intervals are also not overlapping with each other. So we can claim that binary encoding performs better.\n",
    "\n",
    "**Reason**\n",
    "In case of frequency encoding the model gets more confused there by decreasing the truepositives.  Becuase more number of words doesn't mean that the word is the very significant in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cm10 = random_cm(X, y, num_tests = 10)\n",
    "# plot_confusion_matrix(cm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(cm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 (a)\n",
    "\n",
    "Modify the partial code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_random_mean_ci(X, y, num_tests):\n",
    "    # train_results is a list of train accuracy results for the differrent random splits of the dataset\n",
    "    train_results = []\n",
    "    \n",
    "    # test_results is a list of test accuracy results for the differrent random splits of the dataset\n",
    "    test_results = []\n",
    "    \n",
    "    for i in range(0,num_tests):\n",
    "    \n",
    "        # split to train and test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,1000))\n",
    "\n",
    "        # train a logistic regression classifier\n",
    "        #clf = BernoulliNB().fit(X_train, y_train)\n",
    "        #clf = GaussianNB().fit(X_train, y_train)\n",
    "        clf = MultinomialNB().fit(X_train, y_train)\n",
    "        #clf = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "\n",
    "        # predict on train and test set\n",
    "        y_train_predict = clf.predict(X_train)\n",
    "        y_test_predict = clf.predict(X_test)\n",
    "\n",
    "        # calculate train and test accuracy\n",
    "        train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "        train_results.append(train_accuracy)\n",
    "        test_results.append(test_accuracy)\n",
    "    \n",
    "    # calculate the train mean and the 95% confidence interval for the list of results\n",
    "    train_mean = np.mean(train_results)\n",
    "    train_ci_low, train_ci_high = stats.t.interval(0.95, len(train_results)-1, loc=train_mean, scale=stats.sem(train_results))\n",
    "    \n",
    "    # calculate the test mean and the 95% confidence interval for the list of results\n",
    "    test_mean = np.mean(test_results)\n",
    "    test_ci_low, test_ci_high = stats.t.interval(0.95, len(test_results)-1, loc=test_mean, scale=stats.sem(test_results))\n",
    "    \n",
    "    # validate return types\n",
    "    assert isinstance(train_mean, float) and isinstance(train_ci_low, float) and isinstance(train_ci_high, float), \"return types\"\n",
    "    assert isinstance(test_mean, float) and isinstance(test_ci_low, float) and isinstance(test_ci_high, float), \"return types\"\n",
    "    \n",
    "    return train_mean, train_ci_low, train_ci_high, test_mean, test_ci_low, test_ci_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 (b)\n",
    "\n",
    "Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean accuracy over 10 random splits: 0.607558762591984\n",
      "Train confidence interval over 10 random splits: [0.600215296422472, 0.6149022287614961]\n",
      "Test mean accuracy over 10 random splits: 0.5429166666666667\n",
      "Test confidence interval over 10 random splits: [0.5353045855186441, 0.5505287478146893]\n"
     ]
    }
   ],
   "source": [
    "train_mean10, train_low10, train_high10, test_mean10, test_low10, test_high10 = nb_random_mean_ci(X, y, num_tests = 10)\n",
    "print(\"Train mean accuracy over 10 random splits: {}\".format(train_mean10))\n",
    "print(\"Train confidence interval over 10 random splits: [{}, {}]\".format(train_low10, train_high10))\n",
    "print(\"Test mean accuracy over 10 random splits: {}\".format(test_mean10))\n",
    "print(\"Test confidence interval over 10 random splits: [{}, {}]\".format(test_low10, test_high10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the Binary encoding instead of naive bayes because Binary encoding performs better on this data.\n",
    "\n",
    "The test has been performed for three different naive bayes methods and the results are\n",
    "\n",
    "**naiveBayes**\n",
    "\n",
    "GaussianNB()\n",
    "1. Train mean accuracy over 10 random splits: 0.604265199685647\n",
    "2. Train confidence interval over 10 random splits: [0.5971044838101806, 0.6114259155611134]\n",
    "3. Test mean accuracy over 10 random splits: 0.5396166666666667\n",
    "4. Test confidence interval over 10 random splits: [0.5332398196984263, 0.5459935136349072]\n",
    "\n",
    "\n",
    "MultinomialNB()\n",
    "1. Train mean accuracy over 10 random splits: 0.7776594984639565\n",
    "2. Train confidence interval over 10 random splits: [0.775886866322964, 0.7794321306049491]\n",
    "3. Test mean accuracy over 10 random splits: 0.7269500000000001\n",
    "4. Test confidence interval over 10 random splits: [0.7237770757397787, 0.7301229242602215]\n",
    "\n",
    "BernoulliNB()\n",
    "\n",
    "1. Train mean accuracy over 10 random splits: 0.6931699649924983\n",
    "2. Train confidence interval over 10 random splits: [0.6904703112019573, 0.6958696187830392]\n",
    "3. Test mean accuracy over 10 random splits: 0.6498666666666667\n",
    "4. Test confidence interval over 10 random splits: [0.6456747562801883, 0.6540585770531451]\n",
    "\n",
    "**Logistic Regression from the above**\n",
    "\n",
    "1. Train mean accuracy over 10 random splits: 0.9347788811888261\n",
    "2. Train confidence interval over 10 random splits: [0.9334638089634528, 0.9360939534141994]\n",
    "3. Test mean accuracy over 10 random splits: 0.7517333333333334\n",
    "4. Test confidence interval over 10 random splits: [0.7479877847692368, 0.75547888189743]\n",
    "\n",
    "\n",
    "we can clearly see that the MultinomialNB() 0.7269 performs better than other naive bayes classifiers.Benoulli performs better on smaller documents.\n",
    "\n",
    "And also Naive bayes performs less than logistic regression because it assumes feautres are independent but, the features here are words which are not completely independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_graduate_student():\n",
    "    # ** Graduate students: change the return value to True **\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 (a)\n",
    "\n",
    "Modify the partial code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_med_data(file_list, num_words = 1000):\n",
    "    import nltk\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    nltk.download(\"wordnet\")\n",
    "    from nltk.corpus import stopwords \n",
    "    nltk.download('stopwords')\n",
    "    sbStem = SnowballStemmer(\"english\")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    news_cnt = Counter()\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            file_words = [sbStem.stem(w) for w in file_words if w.lower() not in stopwords.words('english')]\n",
    "            #file_words = [sbStem.stem(word) for word in file_words]\n",
    "            news_cnt.update(file_words)\n",
    "   \n",
    "   \n",
    "    word_list = [word for (word, freq) in news_cnt.most_common(num_words)]   \n",
    "    \n",
    "    # Create a binary encoding of dataset based on the selected features (X)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for file_path in file_list:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            file_data = file.read()\n",
    "            file_data = clean_file_text(file_data)\n",
    "            file_words = tokenizer.tokenize(file_data)\n",
    "            file_words = [sbStem.stem(word) for word in file_words]\n",
    "            df_rows.append([1 if word in file_words else 0 for word in word_list])      \n",
    "    X = pd.DataFrame(df_rows, columns = word_list)\n",
    "    \n",
    "    # Create a dataframe of targets (y)\n",
    "    y = [1 if get_topic_name(file_path) == \"sci.med\" else 0 for file_path in file_list]  \n",
    "        \n",
    "#     X = None\n",
    "#     y = None\n",
    "    \n",
    "    # validate return types\n",
    "    assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"return types\"\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 (b)\n",
    "\n",
    "Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nagaraja993\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nagaraja993\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Train mean accuracy over 10 random splits: 0.9913338572551261\n",
      "Train confidence interval over 10 random splits: [0.9909431057066687, 0.9917246088035836]\n",
      "Test mean accuracy over 10 random splits: 0.9730833333333333\n",
      "Test confidence interval over 10 random splits: [0.9718619520791139, 0.9743047145875527]\n"
     ]
    }
   ],
   "source": [
    "X, y = binary_med_data(all_files)\n",
    "train_mean10, train_low10, train_high10, test_mean10, test_low10, test_high10 = random_mean_ci(X, y, num_tests = 10)\n",
    "print(\"Train mean accuracy over 10 random splits: {}\".format(train_mean10))\n",
    "print(\"Train confidence interval over 10 random splits: [{}, {}]\".format(train_low10, train_high10))\n",
    "print(\"Test mean accuracy over 10 random splits: {}\".format(test_mean10))\n",
    "print(\"Test confidence interval over 10 random splits: [{}, {}]\".format(test_low10, test_high10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are \n",
    "\n",
    "1. Train mean accuracy over 10 random splits: 0.9913338572551261\n",
    "2. Train confidence interval over 10 random splits: [0.9909431057066687, 0.9917246088035836]\n",
    "3. Test mean accuracy over 10 random splits: 0.9730833333333333\n",
    "4. Test confidence interval over 10 random splits: [0.9718619520791139, 0.9743047145875527]\n",
    "\n",
    "The multiclass logistic regression  \n",
    "\n",
    "1. Train mean accuracy over 10 random splits: 0.9347788811888261\n",
    "2. Train confidence interval over 10 random splits: [0.9334638089634528, 0.9360939534141994]\n",
    "3. Test mean accuracy over 10 random splits: 0.7517333333333334\n",
    "4. Test confidence interval over 10 random splits: [0.7479877847692368, 0.75547888189743]\n",
    "\n",
    "\n",
    "We can see that the test accuracy of binary is 0.97 which is greater than 0.75. But the number of \"scimed\" class documents is 1000. This is 5% (1000/19997) so even we assume that everything is predicted as non scimed we should have 95% accuracy. The data is highly skewed and this leads to better overall accuracy in comparision to the multiclass.\n",
    "\n",
    "If we see the confusion matrix\n",
    "\n",
    "The binary confusion matrix gives TP as 190\n",
    "The multiclass confusion matrix gives TP (average of 10 trials) as = 232.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cm = confusion_matrix(y_test, y_test_predict)\n",
    "#pd.DataFrame(cm)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
